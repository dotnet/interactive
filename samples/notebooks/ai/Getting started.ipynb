{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d71d258b",
   "metadata": {},
   "source": [
    "# .NET Interactive AI Getting started Guide\n",
    "\n",
    "This guide will help configure your Azure OpenAI resources for use with the .NET Interactive AI extensions. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbda2ad0",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- [Azure Account](https://aka.ms/free)\n",
    "- [Azure OpenAI Service](https://learn.microsoft.com/azure/cognitive-services/openai/overview#how-do-i-get-access-to-azure-openai)\n",
    "    - [Deployment](https://learn.microsoft.com/azure/cognitive-services/openai/how-to/create-resource)\n",
    "        - GPT\n",
    "        - ChatGPT\n",
    "        - Embeddings\n",
    "    - DALL-E\n",
    "\n",
    "For more details on getting your endpoint and key values, see the [Azure OpenAI documentation](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/quickstart?tabs=command-line&pivots=programming-language-csharp#retrieve-key-and-endpoint)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db86954d",
   "metadata": {},
   "source": [
    "## A brief guide\n",
    "There are different types of kernels\n",
    " - SkillKernel\n",
    " - TextCompletionKernel\n",
    " - KnowledgeKernel\n",
    " - ImageGenerationKernel\n",
    " - ChatCompletion\n",
    " - VectorStore\n",
    "\n",
    "### Skill kernel\n",
    "It is used by the `TextCompletionKernel`, this kernel is used to define prompt templates that can be composed and used by the `TextCompletionKernel`\n",
    "### TextCompletionKernel\n",
    "The `TextCompletionKernel` accepts prompts and uses a LLM to generate the answer. The kernel can take use the `Skill kernel`'s prompt templates to calculate the answers.\n",
    "If is conencted with a `KnowledgeKernel` then it is also automatically fetching relevant facts and uses them in the answer (automatic RAG).\n",
    "### ImageGenerationKernel\n",
    "Uses DALL-E 2 to generate images from the prompt\n",
    "### ChatCompletion\n",
    "The `ChatCompletion` keeps track of the conversation history. If connected with a `KnowledgeKernel` each conversation turn is marked with the text embeddings for both teh user message and the answer. These text embeddings can be used to:\n",
    " - track topic count\n",
    " - filter out previous turns that have low relevance with current question (increases focus and reduces token usage)\n",
    "### KnowledgeKernel\n",
    "It uses a `text embedding generator` model to calcuate text embeddings and then store the knowledge using and instance of `VectorStore` Kernel (which is require). When creating a new `KnowledgeKernel` it is possible to reuse a instance of `VectorStore`, this is useful when we want to reuse previous data and not recompute the all knowledge.\n",
    "This kernel is able to store data from verbatim input in a cell, from disk and from url. It also allows to process incoming knowledge and derive more facts. During knowledge processing you can calso use the other AI kernels to generate additional facts.\n",
    "\n",
    " \n",
    "```mermaid\n",
    "---\n",
    "title: Kernel relationships\n",
    "---\n",
    "classDiagram\n",
    "    KnowledgeKernel <.. ChatCompletion \n",
    "    KnowledgeKernel <.. TextCompletionKernel\n",
    "    TextCompletionKernel --> SkillKernel\n",
    "    KnowledgeKernel --> VectorStore\n",
    "    class SkillKernel\n",
    "    class TextCompletionKernel\n",
    "    class KnowledgeKernel\n",
    "    class VectorStore\n",
    "    class ChatCompletion\n",
    "    class ImageGenerationKernel\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba32a53f",
   "metadata": {},
   "source": [
    "## Connecting kernels\n",
    "\n",
    "We will now use the api key, endpoint, and deployment names to create kernels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6695eab",
   "metadata": {},
   "source": [
    "## Connecting kernels\n",
    "\n",
    "We will now use the api key, endpoint, and deployment names to create kernels\n",
    "\n",
    "Get the following valuesfrom teh Azure portal:\n",
    "\n",
    "- Your Azure OpenAI endpoint.\n",
    "- Your Azure OpenAI key.\n",
    "- Your Azure OpenAI GPT text completion model name (i.e. text-davinci-003).\n",
    "- Your Azure OpenAI ChatGPT model name (i.e. gpt35-turbo).\n",
    "- Your Azure OpenAI Embedding model name (i.e. text-embedding-ada-002)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a82da11",
   "metadata": {},
   "source": [
    "### Add NuGet package source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#!value --name key\n",
    "YOUR AZURE OPEN AI KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#!value --name endpoint\n",
    "https://your-enpoint.openai.azure.com/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bba11b7",
   "metadata": {},
   "source": [
    "### Install .NET Interactive AI extension NuGet package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div><strong>Restore sources</strong><ul><li><span>https://pkgs.dev.azure.com/dnceng/public/_packaging/dotnet-tools/nuget/v3/index.json</span></li></ul></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.DotNet.Interactive.AI, 1.0.0-beta.23468.2</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading extension script from `C:\\Users\\dicolomb\\.nuget\\packages\\microsoft.dotnet.interactive.ai\\1.0.0-beta.23468.2\\interactive-extensions\\dotnet\\extension.dib`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Added magic commands \r\n",
       ". `#!connect azure-openai`\r\n",
       ". `#!connect openai`.\r\n",
       ". `#!connect huggingface`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading extensions from `C:\\Users\\dicolomb\\.nuget\\packages\\skiasharp\\2.88.5\\interactive-extensions\\dotnet\\SkiaSharp.DotNet.Interactive.dll`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading extension script from `C:\\Users\\dicolomb\\.nuget\\packages\\duckdb.interactiveextension\\1.0.108\\interactive-extensions\\dotnet\\extension.dib`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<details><summary>Query DuckDB databases.</summary>\r\n",
       "    <p>This extension adds support for connecting to <a href=\"https://duckdb.org/\">DuckDB</a> databases using the <code>#!connect duckdb</code> magic command. ADO.NET support via <a href=\"https://github.com/Giorgi/DuckDB.NET\">DuckDB.NET</a> project</p>\r\n",
       "    </details>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget:Microsoft.DotNet.Interactive.AI, *-*\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a45a177",
   "metadata": {},
   "source": [
    "### Connect to you deployemnts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c9d0c6",
   "metadata": {},
   "source": [
    "connect the TextEmbedding model (for example `text-embedding-ada-002`) to create a `Knowledge` kernel. it will be called `knowledge`. by default this command will also create a `VectorStore` kernel using the `DuckDBVectorStore` implementation and a `DuckDB` kernel too. \n",
    "\n",
    "The `VectorStore` kernel will allow to query vectors, export and import knowledge, while the `DuckDB` kernel is providing SQL access to the in memory DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kernel added: #!knowledge(duckDbVectorRAW)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Kernel added: #!knowledge(duckDbVector)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Kernel added: #!knowledge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!connect azure-openai --model-type TextEmbeddingGenerator --kernel-name knowledge --api-key @value:key --endpoint @value:endpoint --deployment text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d36ff7",
   "metadata": {},
   "source": [
    "if you want connect the TextCompletion model (for example ` text-davinci-003`) to create a `TextCompletion` kernel. it will be called `textCompletion`. This also create a `Skill` kernel named `textCompletion(skill)` and using the option `--use-knowledge knowledge` we are conencting the `textCompletion` with the `Knowledge` kernel `knowledge`. This will use relevants facts stored in the knowledge to augmente the prompts (this atchitecture is called (RAG)[https://learn.microsoft.com/en-us/azure/machine-learning/concept-retrieval-augmented-generation?view=azureml-api-2])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kernel added: #!textCompletion(skill)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Kernel added: #!textCompletion"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!connect azure-openai --model-type TextCompletion --kernel-name textCompletion --api-key @value:key --endpoint @value:endpoint --deployment text-davinci-003 --use-knowledge knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fe1f7f",
   "metadata": {},
   "source": [
    "if you have a chatGPT model available you don't need to deploy a `TextCompletion`  model. Connecting a `ChatCompletion` kernel will also create a `TextCompletion` kernel and a `Skill` kernel. \n",
    "At this moment the `ChatCompletion` is implementing a chat loop, there is no implicit `RAG` behaviour and the prompts templates won't be used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kernel added: #!chat(skill)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Kernel added: #!chat(text)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Kernel added: #!chat"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!connect azure-openai --model-type ChatCompletion --kernel-name chat --api-key @value:key --endpoint @value:endpoint --deployment gtp-35-turbo --use-knowledge knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c9321b",
   "metadata": {},
   "source": [
    "If you have access to the  `DALL-E` model in Azure Open Ai then you can connect it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kernel added: #!image"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!connect azure-openai --model-type ImageGenerator --kernel-name image --api-key @value:key --endpoint @value:endpoint --deployment DALL-E"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb6973f7",
   "metadata": {},
   "source": [
    "### Generate responses using models\n",
    "\n",
    "Select a `TextCompletion` or `ChatCompletion` kernel and send your prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "openai(text)"
    },
    "polyglot_notebook": {
     "kernelName": "openai(text)"
    }
   },
   "outputs": [],
   "source": [
    "Who develops .NET Interactive?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4c91a",
   "metadata": {},
   "source": [
    "\n",
    "### Kernel Apis\n",
    "#### Skill Kernel\n",
    "This kernel enabled the definition of prompt templates submitting code like the following snippet\n",
    "```\n",
    "#!function stylist --skill writer\n",
    "Rewrite the following text in the style of {{$person}}:\n",
    "[BEGIN TEXT]\n",
    "{{$input}}\n",
    "[END TEXT]\n",
    "Please write it in verse.\n",
    "```\n",
    "The argument `stylist` is the name of this template; templates can be grouped by skill using the `--skill` option. To define template parameters use the syntax `{{$PARAMETER_NAME}}`. Once the prompt template is evaluate it is ready for use, Look at the `POLYGLOT NOTEBOOK:VARIABLES` (use can use the button `Variables` to open it) and you will see the templates and their list of parameters.\n",
    "To use the prompts you will need to submit some text to a `TextCompletion` Kernel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dotnet_interactive": {
     "language": "textCompletion(skill)"
    },
    "polyglot_notebook": {
     "kernelName": "textCompletion(skill)"
    }
   },
   "outputs": [],
   "source": [
    "#!function stylist --skill writer\n",
    "Answer the question in the style of {{$person}}:\n",
    "[BEGIN TEXT]\n",
    "{{$input}}\n",
    "[END TEXT]\n",
    "Please write it in verse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c4a80",
   "metadata": {},
   "source": [
    "#### TextCompletion Kernel\n",
    "This kernel will use the LLM to evaluate prompts. To use it just evaluate the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "textCompletion"
    },
    "polyglot_notebook": {
     "kernelName": "textCompletion"
    }
   },
   "outputs": [],
   "source": [
    "Who develops .NET Interactive?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93055755",
   "metadata": {},
   "source": [
    "let's do the same but using the prompt template `stylist`. Note that using the `#!set` magic command we can set the template parameter `person`, in this case an input is required to continus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "textCompletion"
    },
    "polyglot_notebook": {
     "kernelName": "textCompletion"
    }
   },
   "outputs": [],
   "source": [
    "#!set --name person --value @input:\"Whose style would you like to summarize this in?\"\n",
    "#!use-skills function.writer.stylist\n",
    ".NET Interactive engine can be used many ways.\n",
    "* It takes messages, routes them to subkernels, and can format returned data.\n",
    "* Messages are initiated via a host (like Polyglot Notebooks).\n",
    "* Subkernels can be a bunch of different languages (including Mermaid).\n",
    "* Subkernels can share data.\n",
    "* Subkernels can be running in different processes and on different machines.\n",
    "* We'd love your ideas on how we can leverage this for developers."
   ]
  }
 ],
 "metadata": {
  "custom": {
   "cells": [],
   "metadata": {
    "kernelspec": {
     "display_name": ".NET (C#)",
     "language": "C#",
     "name": ".net-csharp"
    },
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelInfo": {
      "defaultKernelName": "csharp",
      "items": [
       {
        "aliases": [],
        "languageName": "csharp",
        "name": "csharp"
       }
      ]
     }
    }
   },
   "nbformat": 4,
   "nbformat_minor": 2
  },
  "indentAmount": " ",
  "kernelInfo": {
   "defaultKernelName": null,
   "items": [
    {
     "aliases": [
      "c#",
      "cs"
     ],
     "languageName": "C#",
     "name": "csharp"
    },
    {
     "aliases": [
      "f#",
      "fs"
     ],
     "languageName": "F#",
     "name": "fsharp"
    },
    {
     "languageName": "HTML",
     "name": "html"
    },
    {
     "languageName": "HTTP",
     "name": "http"
    },
    {
     "aliases": [
      "js"
     ],
     "languageName": "JavaScript",
     "name": "javascript"
    },
    {
     "languageName": "KQL",
     "name": "kql"
    },
    {
     "languageName": "Mermaid",
     "name": "mermaid"
    },
    {
     "aliases": [
      "powershell"
     ],
     "languageName": "PowerShell",
     "name": "pwsh"
    },
    {
     "languageName": "SQL",
     "name": "sql"
    },
    {
     "name": "value"
    }
   ]
  },
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
